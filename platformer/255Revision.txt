-----------------
cross correlation:
add all values,
normalise values (when rgb, find min and max out of all, then normalise individually)

for edge detection, you combine the sobel using equations, not adding. you find teh gradients etc

gausian for any size filter
G(x) = e^(-x*x/2st^2)
-------------------------
lighting equations:


ambient light:
intensity * ambient light
eg 1*0.3



diffuse light:
find vector from intersection to light source
find dot product of this to the normal vector
intensity factor*diffusion factor

-----------------------
representing 3d shapes:
triangular strips
compact n triangles represented using n+2 vertices
-transmission to gpu is lower
- very efficient when drawing (particularly in hardware)
- can be hard to create triangle strips from arbitrary geometry


pointers to vertex list:
0 = (1,1,1)
1 = (1,-1,1)
then 1,0
 0,1 etc 
(same as explicit representation but with pointers)
advantages: 3d transformations of just 8 vertices. no rounding errors.
drawbacks: (like with explicit)24 edges (rather than 12), extra processing during modelling

explicit representation
(0,0,0) (0,0,1) etc
- drawbacks: 3d transformations of 24 vertices (not 8), draw 24 edges (rather than 12)

---------------------------
dithering:

diffusion dithering
round up and down, taking the result to the right of the pixel
snaking left then right each row

steinberg dithering


-------------------
ray sphere intersection

----------------------
histogram equalisation
total number of pixels in image = h*w
number of grey levels = g_levels
ideal histogram is flat
ideal number of pixels at each level: p_num = (h*w)/g_levels

mapping F:
if t(i) is the atual number of pixels at all old grey levels up to and including grey level i, then
F(i) = (g_levels*t(i))/(h*w)-1       (min 0)
t(i) is the cumulative distrubution function

convert RGB to HSV
build histogram on V (brightness)
equalise V
convert HSV back to RGB
display


-----------------
bounding volumes
hierarchy

automatic: 
octree

placed in box, then divided into 8, then divide furhter going in

kd-tree
cut in halves , not necisarily in the center
-bsp trees: cut is a plane not a cube

------

volume rendering
cast a ray into the 3d array of voxels for each pixel in the final image.
interpolate the sampled voxels in each ray where it doesnt perfectly align with the ray.
shade each voxel in the ray based on the orientation relative to surfaces of the model and the position of hte light
compose the voxels on top of eachother with lowered opacity so they have some input into the final pixel.

maximum intensity projection
cast a ray at each voxel on one of the sides of the 3d array, taking the largest colour value for each.
all values are normalised and placed in a 2d array for the final image.

-----
anti aliasing
use the vector of the lines, 
find the percent coverage of the line, 
set this pixel to that % of the colour.

super sampling
take a line and take samples at regular intervalues within each pixel.
if it is in the line, colour with one colour. if the other, colour differently.
then sum the colour of the samples and make that the new colour of the pixel.
- more samples : give better images, take much longer to compute, 4x4 samples will take 16 times longer.

adaptive supersampling
decide threshold (eg t=20) 
sample the scene at each pixel corner. (averaging the touching pixels for that corner)
if the max - min of these is <= t then pixel colour = average
- otherwise, recursively take 5 (in between old and middle of all) additional samples in the upper right 
- stop when a limit is reached or the <=t is met
- final pixel is average of all samples.

-----
sampling positions

grid

random (stochastic sampling)

jitter

poisson-disk

-------
look up table
gamma correction
Math.pow(index, 1/new gamma


-----------
derivative / gradient / slope
gradient is approx change in y over change in x as the sample gets smaller